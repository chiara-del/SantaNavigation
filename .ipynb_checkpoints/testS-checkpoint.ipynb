{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110afb8d-9f90-4817-ba76-f675cf5a2317",
   "metadata": {},
   "source": [
    "# testS\n",
    "Here I put some test that was sussexfull with all my reasoning\n",
    "\n",
    "\n",
    "(1) here we can select the points that are the vertices of the enviroment to calibrate the camera and then work correctly!\n",
    "\n",
    "\n",
    "(2) here I'm trying to use the webcam to do detection of the symbol on the thymio and the obstacle in the enviroment\n",
    "--> I notice that the thymio identification works quite well but for the obstacle no. Maybe we should reason better at the design choices and at the filtering we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d48091-a60f-4972-9ef0-2abdd412610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening webcam index 0...\n",
      "\n",
      "Webcam open.\n",
      "Press 's' to snapshot the current frame for calibration.\n",
      "Snapshot taken! Please close the preview window.\n",
      "\n",
      "--- INSTRUCTIONS ---\n",
      "Click on the 4 corners of your robot arena in this order:\n",
      "  1. Top-Left\n",
      "  2. Top-Right\n",
      "  3. Bottom-Right\n",
      "  4. Bottom-Left\n",
      "After 4 clicks, press 'c' to continue.\n",
      "Point 1 added: (282, 241)\n",
      "Point 2 added: (964, 203)\n",
      "Point 3 added: (937, 560)\n",
      "Point 4 added: (341, 553)\n",
      "All 4 points selected. Press 'c' to calculate the transform.\n",
      "Calculating perspective transform matrix...\n",
      "Matrix calculated successfully!\n",
      "\n",
      "Starting the real-time top-down feed.\n",
      "Press 'q' in the 'Top-Down Map' window to quit.\n",
      "Cleaning up and closing windows.\n"
     ]
    }
   ],
   "source": [
    "# (1)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "\n",
    "# Set to True to use the webcam, False to use a static image\n",
    "USE_WEBCAM = True\n",
    "\n",
    "# Your Aukey webcam is likely index 0, but it could be 1, 2, etc.\n",
    "# Try changing this if 0 doesn't work.\n",
    "CAMERA_INDEX = 0 \n",
    "\n",
    "# Path to your static image (if USE_WEBCAM is False)\n",
    "IMAGE_PATH = \"prova.jpg\" \n",
    "\n",
    "# Desired output resolution for your top-down map\n",
    "# A 4:3 ratio is common, but you can change this\n",
    "MAP_WIDTH = 800\n",
    "MAP_HEIGHT = 600\n",
    "\n",
    "# --- 2. GLOBAL VARIABLES ---\n",
    "\n",
    "# List to store the 4 clicked points (source points)\n",
    "src_points = []\n",
    "# The image we will use for picking points\n",
    "calibration_frame = None\n",
    "\n",
    "# --- 3. MOUSE CALLBACK FUNCTION ---\n",
    "\n",
    "def click_event(event, x, y, flags, params):\n",
    "    \"\"\"\n",
    "    Handles mouse clicks. \n",
    "    Saves the (x, y) coordinates of 4 clicks.\n",
    "    \"\"\"\n",
    "    global src_points, calibration_frame\n",
    "    \n",
    "    # Check if the left mouse button was clicked\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        \n",
    "        if len(src_points) < 4:\n",
    "            # Add the clicked point to the list\n",
    "            src_points.append((x, y))\n",
    "            \n",
    "            # Draw a circle on the image to show feedback\n",
    "            cv2.circle(calibration_frame, (x, y), 5, (0, 255, 0), -1)\n",
    "            cv2.imshow(\"Source Image - Click 4 Corners\", calibration_frame)\n",
    "            print(f\"Point {len(src_points)} added: ({x}, {y})\")\n",
    "        \n",
    "        if len(src_points) == 4:\n",
    "            print(\"All 4 points selected. Press 'c' to calculate the transform.\")\n",
    "\n",
    "# --- 4. MAIN SCRIPT ---\n",
    "\n",
    "# --- Step 4a: Get the image for calibration ---\n",
    "\n",
    "if USE_WEBCAM:\n",
    "    print(f\"Opening webcam index {CAMERA_INDEX}...\")\n",
    "    cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "    \n",
    "    # Optional: Set high resolution for your 1080p camera\n",
    "    # This might slow down processing, but gives better calibration\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open webcam index {CAMERA_INDEX}.\")\n",
    "        print(\"Try changing CAMERA_INDEX to 1 or 2.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\nWebcam open.\")\n",
    "    print(\"Press 's' to snapshot the current frame for calibration.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Can't receive frame. Exiting...\")\n",
    "            exit()\n",
    "        \n",
    "        # Show a small preview\n",
    "        preview = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        cv2.imshow(\"Webcam Preview - Press 's' to snapshot\", preview)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "            calibration_frame = frame.copy()\n",
    "            print(\"Snapshot taken! Please close the preview window.\")\n",
    "            cv2.destroyWindow(\"Webcam Preview - Press 's' to snapshot\")\n",
    "            break\n",
    "else:\n",
    "    print(f\"Loading image from {IMAGE_PATH}...\")\n",
    "    calibration_frame = cv2.imread(IMAGE_PATH)\n",
    "    if calibration_frame is None:\n",
    "        print(f\"Error: Could not load image from {IMAGE_PATH}.\")\n",
    "        exit()\n",
    "    print(\"Image loaded.\")\n",
    "\n",
    "# --- Step 4b: Select 4 corners ---\n",
    "\n",
    "# Create a window and set the mouse callback\n",
    "cv2.namedWindow(\"Source Image - Click 4 Corners\")\n",
    "cv2.setMouseCallback(\"Source Image - Click 4 Corners\", click_event)\n",
    "\n",
    "print(\"\\n--- INSTRUCTIONS ---\")\n",
    "print(\"Click on the 4 corners of your robot arena in this order:\")\n",
    "print(\"  1. Top-Left\")\n",
    "print(\"  2. Top-Right\")\n",
    "print(\"  3. Bottom-Right\")\n",
    "print(\"  4. Bottom-Left\")\n",
    "print(\"After 4 clicks, press 'c' to continue.\")\n",
    "\n",
    "cv2.imshow(\"Source Image - Click 4 Corners\", calibration_frame)\n",
    "\n",
    "# Wait until 'c' is pressed\n",
    "while True:\n",
    "    if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "        if len(src_points) == 4:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Please click exactly 4 points before pressing 'c'.\")\n",
    "\n",
    "cv2.destroyWindow(\"Source Image - Click 4 Corners\")\n",
    "\n",
    "# --- Step 4c: Calculate Transform Matrix ---\n",
    "\n",
    "print(\"Calculating perspective transform matrix...\")\n",
    "\n",
    "# Convert points to NumPy array in float32 format\n",
    "src_points_np = np.float32(src_points)\n",
    "\n",
    "# Define the 4 destination points (the corners of our output map)\n",
    "dst_points_np = np.float32([\n",
    "    [0, 0],                  # Top-Left\n",
    "    [MAP_WIDTH, 0],          # Top-Right\n",
    "    [MAP_WIDTH, MAP_HEIGHT], # Bottom-Right\n",
    "    [0, MAP_HEIGHT]          # Bottom-Left\n",
    "])\n",
    "\n",
    "# Calculate the perspective transform matrix\n",
    "matrix = cv2.getPerspectiveTransform(src_points_np, dst_points_np)\n",
    "print(\"Matrix calculated successfully!\")\n",
    "np.save(\"my_matrix.npy\", matrix)  #MAYBE NOT HERE\n",
    "\n",
    "\n",
    "# --- Step 4d: Apply Transform in a Loop ---\n",
    "\n",
    "print(\"\\nStarting the real-time top-down feed.\")\n",
    "print(\"Press 'q' in the 'Top-Down Map' window to quit.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        if USE_WEBCAM:\n",
    "            # Read a new frame from the webcam\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Webcam disconnected.\")\n",
    "                break\n",
    "            \n",
    "            # Apply the perspective transform\n",
    "            top_down_map = cv2.warpPerspective(frame, matrix, (MAP_WIDTH, MAP_HEIGHT))\n",
    "            \n",
    "        else:\n",
    "            # For a static image, just apply it once\n",
    "            top_down_map = cv2.warpPerspective(calibration_frame, matrix, (MAP_WIDTH, MAP_HEIGHT))\n",
    "        \n",
    "        # Display the result\n",
    "        cv2.imshow(\"Top-Down Map\", top_down_map)\n",
    "        \n",
    "        # Break loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        # If using a static image, we don't need to loop.\n",
    "        if not USE_WEBCAM:\n",
    "            print(\"Static image transform complete. Press 'q' to quit.\")\n",
    "            cv2.waitKey(0) # Wait forever until a key is pressed\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # --- 5. CLEANUP ---\n",
    "    print(\"Cleaning up and closing windows.\")\n",
    "    if USE_WEBCAM:\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73588db-2e5c-4132-adad-b1d4d8325145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "\n",
    "# Set to True to use the webcam, False to use a static image\n",
    "USE_WEBCAM = True  # <-- CHANGE THIS TO SWITCH\n",
    "\n",
    "# Your Aukey webcam is likely index 0, but it could be 1, 2, etc.\n",
    "CAMERA_INDEX = 0\n",
    "\n",
    "# Path to your static image (if USE_WEBCAM is False)\n",
    "IMAGE_PATH = \"my_arena_image.jpg\"  # <-- SET YOUR TEST IMAGE PATH\n",
    "\n",
    "# --- CONFIGURATION (from Step 1) ---\n",
    "# Desired output resolution for your top-down map\n",
    "MAP_WIDTH = 800\n",
    "MAP_HEIGHT = 600\n",
    "\n",
    "# --- ARUCO CONFIGURATION ---\n",
    "ARUCO_DICT = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "ARUCO_PARAMETERS = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMETERS)\n",
    "\n",
    "THYMIO_MARKER_ID = 0  # ID of the ArUco marker on your Thymio\n",
    "\n",
    "# --- OBSTACLE CONFIGURATION ---\n",
    "# WE HAVE TO REASON ABOUT THE CHOICES WE WANT TO MAKE FOR THE ENVIROMENT\n",
    "OBSTACLE_THRESHOLD_VALUE = 150# Pixels brighter than this become white\n",
    "MIN_OBSTACLE_AREA = 10         # Minimum contour area <--\n",
    "MAX_OBSTACLE_AREA = 5000       # Maximum contour area  <--\n",
    "\n",
    "# --- GOAL CONFIGURATION (Template Matching) ---\n",
    "GOAL_TEMPLATE_PATH = \"goal_template.jpg\"  # Path to your small house image\n",
    "GOAL_MATCH_THRESHOLD = 0.2  # How good the match needs to be (0.0 to 1.0) <-- \n",
    "\n",
    "# --- GLOBAL VARIABLES (for visualization/debugging) ---\n",
    "thymio_position = None\n",
    "thymio_orientation = None  # Angle in degrees\n",
    "obstacles_positions = []\n",
    "goal_position = None\n",
    "\n",
    "# --- FUNCTIONS ---\n",
    "\n",
    "def get_thymio_pose(frame):\n",
    "    \"\"\"Detects the Thymio's ArUco marker and returns its (x,y) and orientation.\"\"\"\n",
    "    corners, ids, rejected = detector.detectMarkers(frame)\n",
    "\n",
    "    if ids is not None and THYMIO_MARKER_ID in ids:\n",
    "        thymio_marker_idx = np.where(ids == THYMIO_MARKER_ID)[0][0]\n",
    "        marker_corners = corners[thymio_marker_idx][0]\n",
    "        \n",
    "        center_x = int(np.mean(marker_corners[:, 0]))\n",
    "        center_y = int(np.mean(marker_corners[:, 1]))\n",
    "        \n",
    "        # ArUco corners order: Top-left, Top-right, Bottom-right, Bottom-left\n",
    "        bottom_mid_x = int((marker_corners[2][0] + marker_corners[3][0]) / 2)\n",
    "        bottom_mid_y = int((marker_corners[2][1] + marker_corners[3][1]) / 2)\n",
    "        \n",
    "        top_mid_x = int((marker_corners[0][0] + marker_corners[1][0]) / 2)\n",
    "        top_mid_y = int((marker_corners[0][1] + marker_corners[1][1]) / 2)\n",
    "        \n",
    "        dx = top_mid_x - bottom_mid_x\n",
    "        dy = top_mid_y - bottom_mid_y\n",
    "        \n",
    "        # Angle 0 degrees \"up\" (negative Y), positive clockwise\n",
    "        angle_rad = math.atan2(dx, -dy) \n",
    "        angle_deg = math.degrees(angle_rad)\n",
    "        \n",
    "        if angle_deg < 0:\n",
    "            angle_deg += 360\n",
    "            \n",
    "        return (center_x, center_y), angle_deg\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def detect_obstacles(frame):\n",
    "    \"\"\"Detects white irregular shapes as obstacles.\"\"\"\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    _, binary_frame = cv2.threshold(gray_frame, OBSTACLE_THRESHOLD_VALUE, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    contours, _ = cv2.findContours(binary_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    detected_obstacles = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if MIN_OBSTACLE_AREA < area < MAX_OBSTACLE_AREA:\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "                detected_obstacles.append((cx, cy))\n",
    "    \n",
    "    return detected_obstacles\n",
    "\n",
    "def detect_goal(frame, template, threshold):\n",
    "    \"\"\"Detects the goal using template matching.\"\"\"\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Check if template has alpha channel, remove it\n",
    "    if template.shape[2] == 4:\n",
    "        template = template[:, :, :3]\n",
    "    \n",
    "    # Check if template is grayscale, if not, convert\n",
    "    if len(template.shape) > 2:\n",
    "        gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_template = template\n",
    "\n",
    "    # Ensure template isn't larger than the frame\n",
    "    if gray_template.shape[0] > gray_frame.shape[0] or gray_template.shape[1] > gray_frame.shape[1]:\n",
    "        print(\"Warning: Goal template is larger than the frame. Skipping detection.\")\n",
    "        return None\n",
    "\n",
    "    res = cv2.matchTemplate(gray_frame, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "    if max_val >= threshold:\n",
    "        top_left = max_loc\n",
    "        h, w = gray_template.shape\n",
    "        center_x = top_left[0] + w // 2\n",
    "        center_y = top_left[1] + h // 2\n",
    "        return (center_x, center_y)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# --- MAIN SCRIPT ---\n",
    "\n",
    "# Load Goal Template (only once)\n",
    "goal_template_img = cv2.imread(GOAL_TEMPLATE_PATH, cv2.IMREAD_UNCHANGED) # Load with alpha if present\n",
    "if goal_template_img is None:\n",
    "    print(f\"Error: Could not load goal template from {GOAL_TEMPLATE_PATH}.\")\n",
    "    exit()\n",
    "print(f\"Goal template loaded from {GOAL_TEMPLATE_PATH}\")\n",
    "\n",
    "# --- You MUST replace this with your actual matrix from Step 1 --- AAAAAAAAA\n",
    "# You can save it from Step 1 using np.save(\"my_matrix.npy\", matrix)\n",
    "# And load it here using matrix = np.load(\"my_matrix.npy\")\n",
    "\n",
    "#matrix = np.load(\"my_matrix.npy\")\n",
    "matrix = np.array([\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0]\n",
    "], dtype=np.float32)\n",
    "print(\"NOTE: Using a DUMMY IDENTITY MATRIX. Replace with your actual perspective transform matrix!\")\n",
    "# --- END DUMMY MATRIX ---\n",
    "\n",
    "\n",
    "# --- Initialize Video Capture or Load Image ---\n",
    "cap = None\n",
    "if USE_WEBCAM:\n",
    "    cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open webcam index {CAMERA_INDEX}.\")\n",
    "        exit()\n",
    "    print(\"\\nStarting localization from webcam. Press 'q' to quit.\")\n",
    "else:\n",
    "    print(f\"\\nStarting localization from image: {IMAGE_PATH}\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frame = None\n",
    "        if USE_WEBCAM:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame from webcam. Exiting...\")\n",
    "                break\n",
    "        else:\n",
    "            # Load the static image\n",
    "            frame = cv2.imread(IMAGE_PATH)\n",
    "            if frame is None:\n",
    "                print(f\"Error: Could not load image from {IMAGE_PATH}.\")\n",
    "                break\n",
    "        \n",
    "        # 1. Apply Perspective Transform (from Step 1)\n",
    "        top_down_map = cv2.warpPerspective(frame, matrix, (MAP_WIDTH, MAP_HEIGHT))\n",
    "\n",
    "        # 2. Detect Thymio\n",
    "        thymio_position, thymio_orientation = get_thymio_pose(top_down_map)\n",
    "\n",
    "        # 3. Detect Obstacles\n",
    "        obstacles_positions = detect_obstacles(top_down_map)\n",
    "\n",
    "        # 4. Detect Goal\n",
    "        goal_position = detect_goal(top_down_map, goal_template_img, GOAL_MATCH_THRESHOLD)\n",
    "\n",
    "        # --- VISUALIZATION (for debugging) ---\n",
    "        display_frame = top_down_map.copy()\n",
    "\n",
    "        # Draw Thymio\n",
    "        if thymio_position is not None and thymio_orientation is not None:\n",
    "            cv2.circle(display_frame, thymio_position, 10, (0, 255, 255), -1) # Yellow\n",
    "            angle_rad = math.radians(thymio_orientation)\n",
    "            end_x = int(thymio_position[0] + 30 * math.sin(angle_rad))\n",
    "            end_y = int(thymio_position[1] - 30 * math.cos(angle_rad))\n",
    "            cv2.arrowedLine(display_frame, thymio_position, (end_x, end_y), (0, 255, 255), 2)\n",
    "            cv2.putText(display_frame, f\"Thymio: ({thymio_position[0]}, {thymio_position[1]}) @ {int(thymio_orientation)} deg\", \n",
    "                        (thymio_position[0] + 15, thymio_position[1] + 15), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "\n",
    "        # Draw Obstacles\n",
    "        for obs_pos in obstacles_positions:\n",
    "            cv2.circle(display_frame, obs_pos, 15, (0, 0, 255), -1) # Red\n",
    "            cv2.putText(display_frame, \"Obstacle\", (obs_pos[0] + 15, obs_pos[1] + 15), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)\n",
    "\n",
    "        # Draw Goal\n",
    "        if goal_position is not None:\n",
    "            cv2.circle(display_frame, goal_position, 15, (255, 0, 0), -1) # Blue\n",
    "            cv2.putText(display_frame, \"Goal\", (goal_position[0] + 15, goal_position[1] + 15), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Top-Down Map with Detections\", display_frame)\n",
    "\n",
    "        # --- Loop Control ---\n",
    "        if USE_WEBCAM:\n",
    "            # For webcam, loop with a 1ms delay\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            # For static image, wait indefinitely for any key press\n",
    "            print(\"Detection complete. Press any key to quit.\")\n",
    "            cv2.waitKey(0)\n",
    "            break # Exit loop after displaying the static image\n",
    "\n",
    "finally:\n",
    "    # --- CLEANUP ---\n",
    "    print(\"Cleaning up and closing windows.\")\n",
    "    if USE_WEBCAM and cap is not None and cap.isOpened():\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
