{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110afb8d-9f90-4817-ba76-f675cf5a2317",
   "metadata": {},
   "source": [
    "# testS\n",
    "Here I put some test that was sussexfull with all my reasoning\n",
    "\n",
    "\n",
    "(1) here we can select the points that are the vertices of the enviroment to calibrate the camera and then work correctly!\n",
    "\n",
    "\n",
    "(2) here I'm trying to use the webcam to do detection of the symbol on the thymio and the obstacle in the enviroment\n",
    "--> I notice that the thymio identification works quite well but for the obstacle no. Maybe we should reason better at the design choices and at the filtering we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1d48091-a60f-4972-9ef0-2abdd412610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening webcam index 0...\n",
      "\n",
      "Webcam open.\n",
      "Press 's' to snapshot the current frame for calibration.\n",
      "Snapshot taken! Please close the preview window.\n",
      "\n",
      "--- INSTRUCTIONS ---\n",
      "Click on the 4 corners of your robot arena in this order:\n",
      "  1. Top-Left\n",
      "  2. Top-Right\n",
      "  3. Bottom-Right\n",
      "  4. Bottom-Left\n",
      "After 4 clicks, press 'c' to continue.\n",
      "Point 1 added: (381, 236)\n",
      "Point 2 added: (797, 210)\n",
      "Point 3 added: (768, 576)\n",
      "Point 4 added: (384, 568)\n",
      "All 4 points selected. Press 'c' to calculate the transform.\n",
      "Calculating perspective transform matrix...\n",
      "Matrix calculated successfully!\n",
      "\n",
      "Starting the real-time top-down feed.\n",
      "Press 'q' in the 'Top-Down Map' window to quit.\n",
      "Cleaning up and closing windows.\n"
     ]
    }
   ],
   "source": [
    "# (1)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "\n",
    "# Set to True to use the webcam, False to use a static image\n",
    "USE_WEBCAM = True\n",
    "\n",
    "# Your Aukey webcam is likely index 0, but it could be 1, 2, etc.\n",
    "# Try changing this if 0 doesn't work.\n",
    "CAMERA_INDEX = 0 \n",
    "\n",
    "# Path to your static image (if USE_WEBCAM is False)\n",
    "IMAGE_PATH = \"prova.jpg\" \n",
    "\n",
    "# Desired output resolution for your top-down map\n",
    "# A 4:3 ratio is common, but you can change this\n",
    "MAP_WIDTH = 800\n",
    "MAP_HEIGHT = 600\n",
    "\n",
    "# --- 2. GLOBAL VARIABLES ---\n",
    "\n",
    "# List to store the 4 clicked points (source points)\n",
    "src_points = []\n",
    "# The image we will use for picking points\n",
    "calibration_frame = None\n",
    "\n",
    "# --- 3. MOUSE CALLBACK FUNCTION ---\n",
    "\n",
    "def click_event(event, x, y, flags, params):\n",
    "    \"\"\"\n",
    "    Handles mouse clicks. \n",
    "    Saves the (x, y) coordinates of 4 clicks.\n",
    "    \"\"\"\n",
    "    global src_points, calibration_frame\n",
    "    \n",
    "    # Check if the left mouse button was clicked\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        \n",
    "        if len(src_points) < 4:\n",
    "            # Add the clicked point to the list\n",
    "            src_points.append((x, y))\n",
    "            \n",
    "            # Draw a circle on the image to show feedback\n",
    "            cv2.circle(calibration_frame, (x, y), 5, (0, 255, 0), -1)\n",
    "            cv2.imshow(\"Source Image - Click 4 Corners\", calibration_frame)\n",
    "            print(f\"Point {len(src_points)} added: ({x}, {y})\")\n",
    "        \n",
    "        if len(src_points) == 4:\n",
    "            print(\"All 4 points selected. Press 'c' to calculate the transform.\")\n",
    "\n",
    "# --- 4. MAIN SCRIPT ---\n",
    "\n",
    "# --- Step 4a: Get the image for calibration ---\n",
    "\n",
    "if USE_WEBCAM:\n",
    "    print(f\"Opening webcam index {CAMERA_INDEX}...\")\n",
    "    cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "    \n",
    "    # Optional: Set high resolution for your 1080p camera\n",
    "    # This might slow down processing, but gives better calibration\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open webcam index {CAMERA_INDEX}.\")\n",
    "        print(\"Try changing CAMERA_INDEX to 1 or 2.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\nWebcam open.\")\n",
    "    print(\"Press 's' to snapshot the current frame for calibration.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Can't receive frame. Exiting...\")\n",
    "            exit()\n",
    "        \n",
    "        # Show a small preview\n",
    "        preview = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        cv2.imshow(\"Webcam Preview - Press 's' to snapshot\", preview)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "            calibration_frame = frame.copy()\n",
    "            print(\"Snapshot taken! Please close the preview window.\")\n",
    "            cv2.destroyWindow(\"Webcam Preview - Press 's' to snapshot\")\n",
    "            break\n",
    "else:\n",
    "    print(f\"Loading image from {IMAGE_PATH}...\")\n",
    "    calibration_frame = cv2.imread(IMAGE_PATH)\n",
    "    if calibration_frame is None:\n",
    "        print(f\"Error: Could not load image from {IMAGE_PATH}.\")\n",
    "        exit()\n",
    "    print(\"Image loaded.\")\n",
    "\n",
    "# --- Step 4b: Select 4 corners ---\n",
    "\n",
    "# Create a window and set the mouse callback\n",
    "cv2.namedWindow(\"Source Image - Click 4 Corners\")\n",
    "cv2.setMouseCallback(\"Source Image - Click 4 Corners\", click_event)\n",
    "\n",
    "print(\"\\n--- INSTRUCTIONS ---\")\n",
    "print(\"Click on the 4 corners of your robot arena in this order:\")\n",
    "print(\"  1. Top-Left\")\n",
    "print(\"  2. Top-Right\")\n",
    "print(\"  3. Bottom-Right\")\n",
    "print(\"  4. Bottom-Left\")\n",
    "print(\"After 4 clicks, press 'c' to continue.\")\n",
    "\n",
    "cv2.imshow(\"Source Image - Click 4 Corners\", calibration_frame)\n",
    "\n",
    "# Wait until 'c' is pressed\n",
    "while True:\n",
    "    if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "        if len(src_points) == 4:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Please click exactly 4 points before pressing 'c'.\")\n",
    "\n",
    "cv2.destroyWindow(\"Source Image - Click 4 Corners\")\n",
    "\n",
    "# --- Step 4c: Calculate Transform Matrix ---\n",
    "\n",
    "print(\"Calculating perspective transform matrix...\")\n",
    "\n",
    "# Convert points to NumPy array in float32 format\n",
    "src_points_np = np.float32(src_points)\n",
    "\n",
    "# Define the 4 destination points (the corners of our output map)\n",
    "dst_points_np = np.float32([\n",
    "    [0, 0],                  # Top-Left\n",
    "    [MAP_WIDTH, 0],          # Top-Right\n",
    "    [MAP_WIDTH, MAP_HEIGHT], # Bottom-Right\n",
    "    [0, MAP_HEIGHT]          # Bottom-Left\n",
    "])\n",
    "\n",
    "# Calculate the perspective transform matrix\n",
    "matrix = cv2.getPerspectiveTransform(src_points_np, dst_points_np)\n",
    "print(\"Matrix calculated successfully!\")\n",
    "np.save(\"my_matrix.npy\", matrix)  #MAYBE NOT HERE\n",
    "\n",
    "\n",
    "# --- Step 4d: Apply Transform in a Loop ---\n",
    "\n",
    "print(\"\\nStarting the real-time top-down feed.\")\n",
    "print(\"Press 'q' in the 'Top-Down Map' window to quit.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        if USE_WEBCAM:\n",
    "            # Read a new frame from the webcam\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Webcam disconnected.\")\n",
    "                break\n",
    "            \n",
    "            # Apply the perspective transform\n",
    "            top_down_map = cv2.warpPerspective(frame, matrix, (MAP_WIDTH, MAP_HEIGHT))\n",
    "            \n",
    "        else:\n",
    "            # For a static image, just apply it once\n",
    "            top_down_map = cv2.warpPerspective(calibration_frame, matrix, (MAP_WIDTH, MAP_HEIGHT))\n",
    "        \n",
    "        # Display the result\n",
    "        cv2.imshow(\"Top-Down Map\", top_down_map)\n",
    "        \n",
    "        # Break loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        # If using a static image, we don't need to loop.\n",
    "        if not USE_WEBCAM:\n",
    "            print(\"Static image transform complete. Press 'q' to quit.\")\n",
    "            cv2.waitKey(0) # Wait forever until a key is pressed\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # --- 5. CLEANUP ---\n",
    "    print(\"Cleaning up and closing windows.\")\n",
    "    if USE_WEBCAM:\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a73588db-2e5c-4132-adad-b1d4d8325145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting localization from webcam. Press 'q' to quit.\n",
      "Cleaning up and closing windows.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "\n",
    "# Set to True to use the webcam, False to use a static image\n",
    "USE_WEBCAM = True  # <-- CHANGE THIS TO SWITCH\n",
    "\n",
    "# Your Aukey webcam is likely index 0\n",
    "CAMERA_INDEX = 0\n",
    "\n",
    "# Path to your static image (if USE_WEBCAM is False)\n",
    "IMAGE_PATH = \"my_arena_image.jpg\"  # <-- SET YOUR TEST IMAGE PATH\n",
    "\n",
    "# --- CONFIGURATION (from Step 1) ---\n",
    "MAP_WIDTH = 800\n",
    "MAP_HEIGHT = 600\n",
    "\n",
    "# --- ARUCO CONFIGURATION ---\n",
    "ARUCO_DICT = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "ARUCO_PARAMETERS = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMETERS)\n",
    "\n",
    "THYMIO_MARKER_ID = 0  # ID of the ArUco marker on your Thymio\n",
    "GOAL_MARKER_ID = 1    # ID of the ArUco marker for the goal\n",
    "\n",
    "# --- OBSTACLE CONFIGURATION (HSV for WHITE) ---\n",
    "# White in HSV has:\n",
    "# - Hue: 0-180 (irrelevant)\n",
    "# - Saturation: 0-25 (very low)\n",
    "# - Value: 200-255 (very high)\n",
    "# These are the ranges we'll use to create a mask.\n",
    "LOWER_WHITE_HSV = np.array([0, 0, 200])\n",
    "UPPER_WHITE_HSV = np.array([180, 25, 255])\n",
    "MIN_OBSTACLE_AREA = 100  # Minimum contour area to be considered an obstacle\n",
    "\n",
    "# --- GLOBAL VARIABLES (for visualization/debugging) ---\n",
    "thymio_pose = None\n",
    "goal_position = None\n",
    "obstacle_contours = []\n",
    "\n",
    "# --- FUNCTIONS ---\n",
    "\n",
    "def detect_aruco_markers(frame):\n",
    "    \"\"\"\n",
    "    Detects ALL ArUco markers and returns their poses in a dictionary\n",
    "    keyed by marker ID.\n",
    "    Returns: {id: ((x, y), angle_deg), ...}\n",
    "    \"\"\"\n",
    "    corners, ids, rejected = detector.detectMarkers(frame)\n",
    "    \n",
    "    poses = {}\n",
    "\n",
    "    if ids is not None:\n",
    "        for i, marker_id in enumerate(ids.flatten()):\n",
    "            marker_corners = corners[i][0]\n",
    "            \n",
    "            # Calculate center\n",
    "            center_x = int(np.mean(marker_corners[:, 0]))\n",
    "            center_y = int(np.mean(marker_corners[:, 1]))\n",
    "            \n",
    "            # Calculate orientation\n",
    "            # ArUco corners order: Top-left, Top-right, Bottom-right, Bottom-left\n",
    "            bottom_mid_x = int((marker_corners[2][0] + marker_corners[3][0]) / 2)\n",
    "            bottom_mid_y = int((marker_corners[2][1] + marker_corners[3][1]) / 2)\n",
    "            \n",
    "            top_mid_x = int((marker_corners[0][0] + marker_corners[1][0]) / 2)\n",
    "            top_mid_y = int((marker_corners[0][1] + marker_corners[1][1]) / 2)\n",
    "            \n",
    "            dx = top_mid_x - bottom_mid_x\n",
    "            dy = top_mid_y - bottom_mid_y\n",
    "            \n",
    "            angle_rad = math.atan2(dx, -dy) \n",
    "            angle_deg = math.degrees(angle_rad)\n",
    "            if angle_deg < 0:\n",
    "                angle_deg += 360\n",
    "                \n",
    "            poses[marker_id] = ((center_x, center_y), angle_deg)\n",
    "    \n",
    "    return poses\n",
    "\n",
    "def detect_obstacles_hsv(frame):\n",
    "    \"\"\"\n",
    "    Detects white obstacles on a colored background using HSV color space.\n",
    "    Returns the raw contours.\n",
    "    \"\"\"\n",
    "    # 1. Convert frame to HSV\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # 2. Create a binary mask for \"white\"\n",
    "    mask = cv2.inRange(hsv_frame, LOWER_WHITE_HSV, UPPER_WHITE_HSV)\n",
    "    \n",
    "    # 3. Clean up the mask (optional but recommended)\n",
    "    #    'MORPH_OPEN' removes small white noise dots (erosion then dilation)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask_cleaned = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # 4. Find contours on the cleaned mask\n",
    "    contours, _ = cv2.findContours(mask_cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # 5. Filter contours by area\n",
    "    valid_contours = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > MIN_OBSTACLE_AREA:\n",
    "            valid_contours.append(contour)\n",
    "    \n",
    "    return valid_contours, mask_cleaned # Return mask for debugging\n",
    "\n",
    "# --- MAIN SCRIPT ---\n",
    "\n",
    "# --- Load Perspective Transform Matrix ---\n",
    "# You MUST replace this with your actual matrix from Step 1\n",
    "# e.g., matrix = np.load(\"my_matrix.npy\")\n",
    "matrix = np.load(\"my_matrix.npy\")\n",
    "#matrix = np.array([\n",
    "    #[1.0, 0.0, 0.0],\n",
    "    #[0.0, 1.0, 0.0],\n",
    "    #[0.0, 0.0, 1.0]\n",
    "#], dtype=np.float32)\n",
    "#print(\"NOTE: Using a DUMMY IDENTITY MATRIX. Replace with your actual perspective transform matrix!\")\n",
    "# --- END DUMMY MATRIX ---\n",
    "\n",
    "\n",
    "# --- Initialize Video Capture or Load Image ---\n",
    "cap = None\n",
    "if USE_WEBCAM:\n",
    "    cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open webcam index {CAMERA_INDEX}.\")\n",
    "        exit()\n",
    "    print(\"\\nStarting localization from webcam. Press 'q' to quit.\")\n",
    "else:\n",
    "    print(f\"\\nStarting localization from image: {IMAGE_PATH}\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frame = None\n",
    "        if USE_WEBCAM:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame from webcam. Exiting...\")\n",
    "                break\n",
    "        else:\n",
    "            # Load the static image\n",
    "            frame = cv2.imread(IMAGE_PATH)\n",
    "            if frame is None:\n",
    "                print(f\"Error: Could not load image from {IMAGE_PATH}.\")\n",
    "                break\n",
    "        \n",
    "        # 1. Apply Perspective Transform (from Step 1)\n",
    "        top_down_map = cv2.warpPerspective(frame, matrix, (MAP_WIDTH, MAP_HEIGHT))\n",
    "\n",
    "        # 2. Detect Thymio and Goal\n",
    "        all_poses = detect_aruco_markers(top_down_map)\n",
    "        \n",
    "        # Reset values\n",
    "        thymio_pose = None\n",
    "        goal_position = None\n",
    "        \n",
    "        if THYMIO_MARKER_ID in all_poses:\n",
    "            thymio_pose = all_poses[THYMIO_MARKER_ID]\n",
    "        \n",
    "        if GOAL_MARKER_ID in all_poses:\n",
    "            goal_position = all_poses[GOAL_MARKER_ID][0] # We only need the (x,y) position\n",
    "\n",
    "        # 3. Detect Obstacles\n",
    "        obstacle_contours, obstacle_mask = detect_obstacles_hsv(top_down_map)\n",
    "\n",
    "        # --- VISUALIZATION (for debugging) ---\n",
    "        display_frame = top_down_map.copy()\n",
    "\n",
    "        # Draw Thymio\n",
    "        if thymio_pose is not None:\n",
    "            pos, angle = thymio_pose\n",
    "            cv2.circle(display_frame, pos, 10, (0, 255, 255), -1) # Yellow\n",
    "            angle_rad = math.radians(angle)\n",
    "            end_x = int(pos[0] + 30 * math.sin(angle_rad))\n",
    "            end_y = int(pos[1] - 30 * math.cos(angle_rad))\n",
    "            cv2.arrowedLine(display_frame, pos, (end_x, end_y), (0, 255, 255), 2)\n",
    "            cv2.putText(display_frame, f\"Thymio (ID {THYMIO_MARKER_ID})\", \n",
    "                        (pos[0] + 15, pos[1]), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "\n",
    "        # Draw Goal\n",
    "        if goal_position is not None:\n",
    "            cv2.circle(display_frame, goal_position, 15, (255, 0, 0), -1) # Blue\n",
    "            cv2.putText(display_frame, f\"Goal (ID {GOAL_MARKER_ID})\", (goal_position[0] + 15, goal_position[1]), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        \n",
    "        # Draw Obstacles\n",
    "        # This draws the PRECISE outlines you asked for\n",
    "        cv2.drawContours(display_frame, obstacle_contours, -1, (0, 0, 255), 2) # Red outlines\n",
    "        \n",
    "        # Display the main frame\n",
    "        cv2.imshow(\"Top-Down Map with Detections\", display_frame)\n",
    "        \n",
    "        # Display the binary mask for tuning/debugging\n",
    "        cv2.imshow(\"Obstacle Mask (Debug)\", obstacle_mask)\n",
    "\n",
    "        # --- Loop Control ---\n",
    "        if USE_WEBCAM:\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            print(\"Detection complete. Press any key to quit.\")\n",
    "            cv2.waitKey(0)\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # --- CLEANUP ---\n",
    "    print(\"Cleaning up and closing windows.\")\n",
    "    if USE_WEBCAM and cap is not None and cap.isOpened():\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed088eb6-6aa3-41d7-a751-d4e0b077f243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating marker with ID=1 from dictionary 0...\n",
      "Successfully saved marker to 'aruco_marker_id_1.png'\n",
      "Press any key to close the preview.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Define the dictionary. We'll use the same one from the detection code.\n",
    "# DICT_4X4_50 is a good choice: 4x4 squares, 50 unique IDs.\n",
    "ARUCO_DICT_NAME = cv2.aruco.DICT_4X4_50\n",
    "\n",
    "# The ID you want to generate.\n",
    "MARKER_ID = 1\n",
    "\n",
    "# The size of the output image in pixels (e.g., 300x300).\n",
    "# Make this large enough for a high-quality print.\n",
    "IMAGE_SIZE = 300\n",
    "\n",
    "# The name of the output file.\n",
    "OUTPUT_FILE = f\"aruco_marker_id_{MARKER_ID}.png\"\n",
    "\n",
    "# --- Generation ---\n",
    "\n",
    "# 1. Get the ArUco dictionary\n",
    "try:\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(ARUCO_DICT_NAME)\n",
    "except AttributeError:\n",
    "    print(f\"Error: Unable to find ArUco dictionary. Make sure you have 'opencv-python-contrib' installed.\")\n",
    "    exit()\n",
    "\n",
    "# 2. Create an empty image (numpy array)\n",
    "# Note: ArUco functions in older OpenCV versions might draw directly.\n",
    "# The modern way is to use `generateImageMarker`.\n",
    "print(f\"Generating marker with ID={MARKER_ID} from dictionary {ARUCO_DICT_NAME}...\")\n",
    "\n",
    "# 3. Generate the marker\n",
    "# This function creates the marker image directly.\n",
    "# The '1' argument is the border size (in bits/modules). 1 is standard.\n",
    "marker_image = cv2.aruco.generateImageMarker(aruco_dict, MARKER_ID, IMAGE_SIZE, borderBits=1)\n",
    "\n",
    "if marker_image is not None:\n",
    "    # 4. Save the image to a file\n",
    "    cv2.imwrite(OUTPUT_FILE, marker_image)\n",
    "    print(f\"Successfully saved marker to '{OUTPUT_FILE}'\")\n",
    "    \n",
    "    # Optional: Display the marker\n",
    "    cv2.imshow(\"ArUco Marker\", marker_image)\n",
    "    print(\"Press any key to close the preview.\")\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Could not generate ArUco marker.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a6745-9522-48f5-b519-388606098edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2272ee0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ada_exam_2024)",
   "language": "python",
   "name": "ada_exam_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
